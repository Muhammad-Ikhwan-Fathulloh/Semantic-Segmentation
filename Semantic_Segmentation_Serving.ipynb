{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jMQTbLhsCy-",
        "outputId": "aeee61c8-f143-4354-b3d6-abc5eae598bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.6 pyngrok-7.2.3 starlette-0.41.3 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install fastapi uvicorn pyngrok torch torchvision Pillow opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWxoxzy6sJ0V",
        "outputId": "4498701f-3cb6-49e9-abd6-28f02f7c330f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: python-multipart\n",
            "Successfully installed python-multipart-0.0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import base64\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio"
      ],
      "metadata": {
        "id": "id9hnkE2sNVd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56eFS7lSvoIe",
        "outputId": "245d232e-1fb6-4977-ffb1-973b4c88455b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from fastapi import FastAPI\n",
        "\n",
        "class SegmentationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegmentationModel, self).__init__()\n",
        "        self.encoder = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.decoder = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/mentoring/Kelas-CV/model/best_model.pth\"\n",
        "model = SegmentationModel()\n",
        "\n",
        "try:\n",
        "    # Load model weights with strict=False to handle mismatches\n",
        "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully.\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Model file not found at {model_path}.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ecC1WTsadu",
        "outputId": "a10f871f-4b48-494d-a2f2-e7a8377c9e24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b25688d73890>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert PIL image to base64\n",
        "def pil_to_base64(image: Image) -> str:\n",
        "    buffer = io.BytesIO()\n",
        "    image.save(buffer, format=\"PNG\")\n",
        "    return base64.b64encode(buffer.getvalue()).decode()\n",
        "\n",
        "# Function to preprocess image for the model\n",
        "def preprocess_image(image: Image) -> torch.Tensor:\n",
        "    # Convert image to numpy and perform necessary transformations here\n",
        "    img = np.array(image) / 255.0  # Normalization example, modify according to your model needs\n",
        "    img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float()  # Convert to torch.Tensor\n",
        "    return img\n",
        "\n",
        "# Function to postprocess model output into mask\n",
        "def postprocess_mask(mask: torch.Tensor) -> Image:\n",
        "    mask = mask.squeeze().detach().numpy()\n",
        "    mask = (mask * 255).astype(np.uint8)  # Rescale the mask to 0-255 range\n",
        "    return Image.fromarray(mask)"
      ],
      "metadata": {
        "id": "5jZDsA7Psozk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model input/output schema\n",
        "class ImageInput(BaseModel):\n",
        "    image_base64: str\n",
        "\n",
        "class ImageOutput(BaseModel):\n",
        "    segmented_image_base64: str\n",
        "\n",
        "# API endpoint for image segmentation\n",
        "@app.post(\"/segment-image/\", response_model=ImageOutput)\n",
        "async def segment_image(file: UploadFile = File(...)):\n",
        "    # Open the image file\n",
        "    image = Image.open(io.BytesIO(await file.read()))\n",
        "\n",
        "    # Preprocess the image for the model\n",
        "    input_tensor = preprocess_image(image)\n",
        "\n",
        "    # Perform model inference\n",
        "    with torch.no_grad():\n",
        "        output_mask = model(input_tensor)  # Run inference\n",
        "\n",
        "    # Postprocess the output mask\n",
        "    mask_image = postprocess_mask(output_mask)\n",
        "\n",
        "    # Convert mask to base64 format\n",
        "    mask_base64 = pil_to_base64(mask_image)\n",
        "\n",
        "    # Return the segmented mask as base64\n",
        "    return {\"segmented_image_base64\": mask_base64}\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"Semantic Segmentation API is running!\"}"
      ],
      "metadata": {
        "id": "CjSWzQarsv5t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tambahkan token ngrok Anda\n",
        "!ngrok config add-authtoken YOUR_NGROK_AUTHTOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQJPnBRez-K8",
        "outputId": "cd51be16-856f-4548-ffa8-2cb62ccfd6ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "# Run the server in a separate thread\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Run the FastAPI server\n",
        "thread = Thread(target=run)\n",
        "thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE0svjZN0wzT",
        "outputId": "9ba250ac-d3a1-462a-c1c7-dddcabeca986"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://6d63-35-192-21-172.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    }
  ]
}